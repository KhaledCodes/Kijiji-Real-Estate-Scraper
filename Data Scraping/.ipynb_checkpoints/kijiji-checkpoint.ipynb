{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib.request\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import random\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "import selenium.webdriver.support.expected_conditions as ec\n",
    "from selenium.webdriver.common.by import By\n",
    "from config import API_KEY\n",
    "from pprint import pprint\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty arrays for data to be scraped\n",
    "addresses = []\n",
    "prices = []\n",
    "urls = []\n",
    "# setup driver\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set min price and max price\n",
    "min_price = \n",
    "max_price = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get number of pages and number of listings\n",
    "driver.get(\"https://www.kijiji.ca/b-room-rental-roommate/city-of-toronto/page-1/c36l1700273?ad=offering&sort=priceAsc&furnished=0&minNumberOfImages=1&price=\" + str(min_price) + \"__\" + str(max_price))\n",
    "showing = driver.find_element_by_class_name(\"showing\")\n",
    "showing_text = showing.text\n",
    "split_showing_text = showing_text.split()\n",
    "split_showing_text[5]\n",
    "number_of_pages = int(split_showing_text[5]) // 40 + 1\n",
    "number_of_pages\n",
    "listings_on_last_page = int(split_showing_text[5]) - 40 * (number_of_pages-1)\n",
    "listings_on_last_page_times_two = listings_on_last_page * 2\n",
    "print('number of listing: ' + split_showing_text[5])\n",
    "print('number of pages: ' + str(number_of_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#odd numbers to prevent duplicates because links are indexed twice\n",
    "odd_numbers = []\n",
    "for n in range(0,80):\n",
    "    if n%2 != 0:\n",
    "        odd_numbers.append(n)\n",
    "        \n",
    "odd_numbers_on_last_page = []\n",
    "for n in range(0,listings_on_last_page_times_two):\n",
    "    if n%2 != 0:\n",
    "        odd_numbers_on_last_page.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list to add page scrape times to find average time it takes to scrape one page\n",
    "scrape_times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape listings on page\n",
    "def scrape_page():\n",
    "    \n",
    "    if i == number_of_pages:\n",
    "        listings = odd_numbers_on_last_page\n",
    "    \n",
    "    else:\n",
    "        listings = odd_numbers\n",
    "    \n",
    "    for j in listings:\n",
    "        address = []\n",
    "        while address == []:\n",
    "            try:\n",
    "                start = time.time()\n",
    "                titles = driver.find_elements_by_class_name(\"title\")\n",
    "                titles[j].click()\n",
    "                wait.until(ec.presence_of_element_located((By.CLASS_NAME, 'address-3617944557')))\n",
    "                current_url = driver.current_url\n",
    "                page = urllib.request.urlopen(current_url)\n",
    "                soup = bs(page, 'html.parser')\n",
    "                address = soup.find(\"span\", class_=\"address-3617944557\")\n",
    "                price = soup.find(\"span\", class_ = \"currentPrice-2842943473\")\n",
    "                #append data to arrays\n",
    "                addresses.append(address.text)\n",
    "                prices.append(price.text)\n",
    "                urls.append(current_url)\n",
    "                stop = time.time()\n",
    "                scrape_time = stop - start\n",
    "                print(\"listing \" + str(int(j/2 + 0.5)) + \" scraped in \" + str(scrape_time) + ' seconds')\n",
    "                scrape_times.append(scrape_time)\n",
    "                #go back to listings page\n",
    "                driver.back() \n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through pages\n",
    "for i in range(1,number_of_pages+1):\n",
    "    print('page ' + str(i))\n",
    "    driver.get(\"https://www.kijiji.ca/b-room-rental-roommate/city-of-toronto/page-\" + str(i) + \"/c36l1700273?ad=offering&sort=priceAsc&furnished=0&minNumberOfImages=1&price=\" + str(min_price) + \"__\" + str(max_price))\n",
    "    time.sleep(2)\n",
    "    scrape_page()\n",
    "    if i == number_of_pages:\n",
    "        print('scrape done')\n",
    "        print('average scrape time per page is ' + str(sum(scrape_times)/len(scrape_times)) + ' seconds')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the lengths of the scraped items\n",
    "len(addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create queries from addresses that were scraped\n",
    "query_addresses = [] \n",
    "for i in range(len(addresses)): \n",
    "    query_address = addresses[i].replace(\" \",\"+\") \n",
    "    query_addresses.append(query_address)\n",
    "\n",
    "len(query_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the url that will be requested from the google maps api\n",
    "target_urls = [] \n",
    "for i in query_addresses: \n",
    "    target_url = \"https://maps.googleapis.com/maps/api/geocode/json?address=\"+ str(i) + \"&key=\" + str(API_KEY) \n",
    "    target_urls.append(target_url) \n",
    "    \n",
    "len(target_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = [] \n",
    "lngs = []\n",
    "responses = []\n",
    "for i in target_urls:\n",
    "    try:\n",
    "        response = requests.get(i)\n",
    "        responses.append(response.json())\n",
    "        lat = response.json()['results'][0]['geometry']['location']['lat']\n",
    "        lats.append(lat)\n",
    "        lng = response.json()['results'][0]['geometry']['location']['lng']\n",
    "        lngs.append(lng)\n",
    "    except:\n",
    "        lat = 43.616\n",
    "        lng = -79.422\n",
    "        lats.append(lat)\n",
    "        lngs.append(lng)\n",
    "        print(target_urls.index(str(i)))\n",
    "        print(i)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if length of lats and lngs equals length of scraped items\n",
    "len(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe from all data \n",
    "df = pd.DataFrame({\"Address\":addresses,\"URL\":urls,\"Price\":prices,\"Latitude\":lats,\"Longitude\":lngs,\"Query Address\":query_addresses}) \n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dataframe to json\n",
    "final = df.to_json() \n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go to https://www.freeformatter.com/json-escape.html and paste the above json and unescape it\n",
    "# then copy the output and paste it in a js file, assigning it to a variable called data, then run a live server\n",
    "# on index.html and you have your interactive map!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
